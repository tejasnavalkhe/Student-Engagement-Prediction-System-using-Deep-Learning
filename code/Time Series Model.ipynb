{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-idvS02OehJH"
      },
      "source": [
        "# Task 3: Time-Series Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions on How to run the model\n",
        "\n",
        "To execute the model, ensure you follow these steps:\n",
        "\n",
        "1. Mount a Google drive to a specified path.\n",
        "2. Navigate to the directory containing this file as your working directory.\n",
        "3. Run all cells one by one except the one which trains the model.\n",
        "4. Before runing the cell make sure to store files of all models which has trained weights in the current directory.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GA4puJyr2flx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1oJgg-jYM2j"
      },
      "source": [
        "## 0. Mounting a drive\n",
        "\n",
        "We'll first mount the drive to the directory '/content/drive'. Afterward, we'll switch the working directory to the folder containing this file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive/Deep Learning/Coursework/Task 3\")"
      ],
      "metadata": {
        "id": "8Mr8blZOohyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5470ca97-d957-44c2-bd87-971ba25245c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import required libraries and load data"
      ],
      "metadata": {
        "id": "JSIHlel6m6hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, concatenate, LSTM, GRU, Dropout, BatchNormalization\n",
        "from keras.models import Sequential, load_model\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import pytz\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Deep Learning/Coursework/Task 3\""
      ],
      "metadata": {
        "id": "pgXtYZSL0wec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function used to load the dataset:\n",
        "\n",
        "def load_data():\n",
        "\n",
        "    # Loading the dataset from csv file:\n",
        "    df = pd.read_csv(f'{ROOT_FOLDER}/UserLog.csv', names=['date_time', 'event_type', 'cluster', 'duration', 'users'])\n",
        "\n",
        "    print('The dataset has been loaded:')\n",
        "    print('The first few rows of dataset: ')\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data()"
      ],
      "metadata": {
        "id": "psI9PP62ENRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa89fb1-abee-4687-fb76-b0f5046303df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has been loaded:\n",
            "The first few rows of dataset: \n",
            "                      date_time event_type cluster  duration  users\n",
            "0  Fri Jan 01 00:00:00 GMT 2010      LOGIN    FELL   1261840      1\n",
            "1  Fri Jan 01 00:00:00 GMT 2010      LOGIN    LAKE  10058927      2\n",
            "2  Fri Jan 01 00:00:00 GMT 2010      LOGIN    SIDE   6868990      3\n",
            "3  Fri Jan 01 00:00:00 GMT 2010      LOGIN    LAKE   2997017      4\n",
            "4  Fri Jan 01 00:00:00 GMT 2010      LOGIN    LAKE   8919800      5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing\n",
        "\n",
        "The time series data I had was inconsistent because some date_time entries were in BST while others were in GMT. Therefore, in this phase, I have standardized them to a single timezone. Subsequently, I encountered white spaces in the event_type and cluster columns, which I promptly eliminated. The pivotal step involved creating a new column called \"interval,\" which calculates the difference between two consecutive seconds. This column will be utilized later in predicting the date_time (Task-1).\n"
      ],
      "metadata": {
        "id": "4NV7WMm28MBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define time zones\n",
        "\n",
        "bst_timezone = pytz.timezone('Europe/London')\n",
        "gmt_timezone = pytz.timezone('GMT')\n",
        "\n",
        "def parse_date(timestamp_str):\n",
        "    # Convert GMT date_times to BST\n",
        "    timestamp = None\n",
        "    try:\n",
        "        # Parse as BST\n",
        "        datetime_obj = datetime.strptime(timestamp_str, '%a %b %d %H:%M:%S BST %Y')\n",
        "        timestamp = bst_timezone.localize(datetime_obj)\n",
        "    except ValueError:\n",
        "        # Parse as GMT, if fails to pass BST\n",
        "        datetime_obj = datetime.strptime(timestamp_str, '%a %b %d %H:%M:%S GMT %Y')\n",
        "        timestamp = gmt_timezone.localize(datetime_obj) + timedelta(hours=1)\n",
        "\n",
        "    if timestamp != None:\n",
        "        original_timestamp = pytz.timezone('UTC').localize(timestamp) if pd.isnull(timestamp) or timestamp.tzinfo is None else timestamp\n",
        "        bst_timestamp = original_timestamp.astimezone(bst_timezone)\n",
        "        return bst_timestamp"
      ],
      "metadata": {
        "id": "6WLiUfzgTfPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(df):\n",
        "\n",
        "    # parse date_time to one timezone (BST):\n",
        "    df['date_time'] = df['date_time'].apply(parse_date)\n",
        "\n",
        "    # Remove trailing spaces:\n",
        "    df['event_type'] = df['event_type'].map(lambda x: x.strip())\n",
        "    df['cluster'] = df['cluster'].map(lambda x: x.strip())\n",
        "\n",
        "    # Initialize LabelEncoder\n",
        "    event_type_encoder, cluster_encoder = LabelEncoder(), LabelEncoder()\n",
        "\n",
        "    # Fit label encoder and transform categories to numerics:\n",
        "    df['event_type'] = event_type_encoder.fit_transform(df['event_type'])\n",
        "    df['cluster'] = cluster_encoder.fit_transform(df['cluster'])\n",
        "\n",
        "    login_duration_scaler = RobustScaler()\n",
        "    df['duration'] = login_duration_scaler.fit_transform(np.array(df['duration']).reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "    df = df.sort_values(by='date_time')\n",
        "\n",
        "    df['interval'] = df['date_time'].diff().dt.total_seconds()\n",
        "    df.dropna(inplace=True)\n",
        "    df['interval'] = df['interval'].astype(int)\n",
        "\n",
        "    interval_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    df['interval'] = interval_scaler.fit_transform(df['interval'].values.reshape(-1, 1))\n",
        "\n",
        "    return df\n",
        "\n",
        "df = preprocessing(df)"
      ],
      "metadata": {
        "id": "X9Kw7ABrIjbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Predicting Date & Time\n",
        "\n",
        "1. I've create a function called `window_sequencing` which will give me the values of `X_test, X_train, y_train, X_val, y_val, X_test, y_test, and date_time object of last row of dataframe`.\n",
        "2. The model has build using several `GRU` layers and `BatchNormalization` and after training the model it's been stored in the file `date_time_model.h5`.\n",
        "3. I've got following result metrics:\n",
        "\n",
        "    R2 score: -0.01706\n",
        "    \n",
        "    Mean squared error: 0.00006\n",
        "\n",
        "    Mean absolute error: 0.00098"
      ],
      "metadata": {
        "id": "qH3oHDn3i6QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Window sequencing\n",
        "def window_sequencing(col, size=10, train_test_split_size=0.2, val_test_size=0.4):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(len(col.values) - size) :\n",
        "      X.append(col.values[i:i+size])  # First 9 points\n",
        "      Y.append(col.values[i+size])    # 10th data point\n",
        "\n",
        "    # Divide dataset into feature and target\n",
        "    X = np.array(X)\n",
        "    y = np.array(Y)\n",
        "\n",
        "    # Split data into training, validation, and testing sets\n",
        "    X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=train_test_split_size, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=val_test_size, shuffle=False)\n",
        "\n",
        "    return df.iloc[-len(X_test)+1].date_time, X_train.reshape(-1, size, 1), y_train, X_val.reshape(-1, size, 1), y_val, X_test.reshape(-1, size, 1), y_test"
      ],
      "metadata": {
        "id": "0AXCrTH9Mleu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_validation_last, X_train, y_train, X_valid, y_valid, X_test, y_test = window_sequencing(df['interval'])\n",
        "\n",
        "print(\"Following are the shapes of data:\\n\")\n",
        "print(f\"X train shape : {X_train.shape}\")\n",
        "print(f\"y train shape : {y_train.shape}\")\n",
        "print(f\"X validation shape : {X_valid.shape}\")\n",
        "print(f\"y validation shape : {y_valid.shape}\")\n",
        "print(f\"X testing shape : {X_test.shape}\")\n",
        "print(f\"y testing shape : {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo4weUJlMlcl",
        "outputId": "615a1a56-1eb3-4071-c383-1dda616a8514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Following are the shapes of data:\n",
            "\n",
            "X train shape : (1967701, 10, 1)\n",
            "y train shape : (1967701,)\n",
            "X validation shape : (295155, 10, 1)\n",
            "y validation shape : (295155,)\n",
            "X testing shape : (196771, 10, 1)\n",
            "y testing shape : (196771,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([\n",
        "    GRU(units=512, input_shape=(10, 1), return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    GRU(units=256, return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    GRU(units=128, return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    GRU(units=256, return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    GRU(units=128, return_sequences=False),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer=Adam(learning_rate=0.001), loss='huber_loss', metrics=['mae', 'mse'])\n",
        "\n",
        "# Summarise the model\n",
        "model1.summary()\n",
        "\n",
        "# Checkpoint creation to save the model\n",
        "checkpoint = ModelCheckpoint(f'{ROOT_FOLDER}/date_time_model.h5', monitor='huber_loss', metrics=['mae'])\n",
        "\n",
        "# Model training\n",
        "history = model1.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40, batch_size=1024, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwXXJYg-U3Gm",
        "outputId": "58cffa9e-5057-4d1c-f040-929736e9f1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 10, 512)           791040    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 10, 512)           2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 512)           0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 10, 256)           591360    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 10, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 256)           0         \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 10, 128)           148224    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 10, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 10, 256)           296448    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 10, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10, 256)           0         \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 128)               148224    \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1984577 (7.57 MB)\n",
            "Trainable params: 1982017 (7.56 MB)\n",
            "Non-trainable params: 2560 (10.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "1922/1922 [==============================] - 43s 16ms/step - loss: 0.0149 - mae: 0.0522 - mse: 0.0340 - val_loss: 8.0203e-06 - val_mae: 5.6660e-04 - val_mse: 1.6041e-05\n",
            "Epoch 2/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.9048e-05 - mae: 0.0014 - mse: 5.8641e-05 - val_loss: 8.6054e-06 - val_mae: 6.1791e-04 - val_mse: 1.7211e-05\n",
            "Epoch 3/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.5938e-05 - mae: 0.0013 - mse: 5.1877e-05 - val_loss: 8.8348e-06 - val_mae: 8.4633e-04 - val_mse: 1.7670e-05\n",
            "Epoch 4/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.6254e-05 - mae: 0.0013 - mse: 5.2508e-05 - val_loss: 7.9054e-06 - val_mae: 7.5373e-04 - val_mse: 1.5811e-05\n",
            "Epoch 5/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.5941e-05 - mae: 0.0012 - mse: 5.1881e-05 - val_loss: 6.8730e-06 - val_mae: 4.8888e-04 - val_mse: 1.3746e-05\n",
            "Epoch 6/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.5713e-05 - mae: 0.0012 - mse: 5.1426e-05 - val_loss: 7.6540e-06 - val_mae: 8.1429e-04 - val_mse: 1.5308e-05\n",
            "Epoch 7/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.4199e-05 - mae: 0.0011 - mse: 4.8398e-05 - val_loss: 7.3899e-06 - val_mae: 8.2566e-04 - val_mse: 1.4780e-05\n",
            "Epoch 8/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.6900e-05 - mae: 0.0012 - mse: 5.3799e-05 - val_loss: 9.1683e-06 - val_mae: 0.0013 - val_mse: 1.8337e-05\n",
            "Epoch 9/40\n",
            "1922/1922 [==============================] - 30s 16ms/step - loss: 2.7622e-05 - mae: 0.0013 - mse: 5.5244e-05 - val_loss: 8.9306e-06 - val_mae: 9.9106e-04 - val_mse: 1.7861e-05\n",
            "Epoch 10/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7620e-05 - mae: 0.0013 - mse: 5.5241e-05 - val_loss: 8.8366e-06 - val_mae: 7.4776e-04 - val_mse: 1.7673e-05\n",
            "Epoch 11/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7613e-05 - mae: 0.0013 - mse: 5.5225e-05 - val_loss: 8.8281e-06 - val_mae: 6.9866e-04 - val_mse: 1.7656e-05\n",
            "Epoch 12/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7612e-05 - mae: 0.0013 - mse: 5.5224e-05 - val_loss: 8.9010e-06 - val_mae: 9.3313e-04 - val_mse: 1.7802e-05\n",
            "Epoch 13/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7608e-05 - mae: 0.0013 - mse: 5.5216e-05 - val_loss: 9.2260e-06 - val_mae: 0.0014 - val_mse: 1.8452e-05\n",
            "Epoch 14/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7612e-05 - mae: 0.0013 - mse: 5.5224e-05 - val_loss: 8.8843e-06 - val_mae: 8.9580e-04 - val_mse: 1.7769e-05\n",
            "Epoch 15/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7608e-05 - mae: 0.0013 - mse: 5.5217e-05 - val_loss: 9.1288e-06 - val_mae: 0.0013 - val_mse: 1.8258e-05\n",
            "Epoch 16/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7610e-05 - mae: 0.0013 - mse: 5.5219e-05 - val_loss: 8.8237e-06 - val_mae: 6.1019e-04 - val_mse: 1.7647e-05\n",
            "Epoch 17/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7618e-05 - mae: 0.0013 - mse: 5.5236e-05 - val_loss: 9.1819e-06 - val_mae: 0.0013 - val_mse: 1.8364e-05\n",
            "Epoch 18/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7618e-05 - mae: 0.0013 - mse: 5.5235e-05 - val_loss: 8.9275e-06 - val_mae: 9.8539e-04 - val_mse: 1.7855e-05\n",
            "Epoch 19/40\n",
            "1922/1922 [==============================] - 30s 16ms/step - loss: 2.7610e-05 - mae: 0.0013 - mse: 5.5220e-05 - val_loss: 9.1230e-06 - val_mae: 0.0013 - val_mse: 1.8246e-05\n",
            "Epoch 20/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7607e-05 - mae: 0.0013 - mse: 5.5215e-05 - val_loss: 8.8248e-06 - val_mae: 6.6675e-04 - val_mse: 1.7650e-05\n",
            "Epoch 21/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7610e-05 - mae: 0.0013 - mse: 5.5219e-05 - val_loss: 9.1350e-06 - val_mae: 0.0013 - val_mse: 1.8270e-05\n",
            "Epoch 22/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7614e-05 - mae: 0.0013 - mse: 5.5228e-05 - val_loss: 8.8968e-06 - val_mae: 9.2403e-04 - val_mse: 1.7794e-05\n",
            "Epoch 23/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7608e-05 - mae: 0.0013 - mse: 5.5216e-05 - val_loss: 8.8481e-06 - val_mae: 7.9365e-04 - val_mse: 1.7696e-05\n",
            "Epoch 24/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7613e-05 - mae: 0.0013 - mse: 5.5226e-05 - val_loss: 8.8325e-06 - val_mae: 7.2659e-04 - val_mse: 1.7665e-05\n",
            "Epoch 25/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7610e-05 - mae: 0.0013 - mse: 5.5219e-05 - val_loss: 9.2286e-06 - val_mae: 0.0014 - val_mse: 1.8457e-05\n",
            "Epoch 26/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7613e-05 - mae: 0.0013 - mse: 5.5226e-05 - val_loss: 8.8568e-06 - val_mae: 8.2270e-04 - val_mse: 1.7714e-05\n",
            "Epoch 27/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7612e-05 - mae: 0.0013 - mse: 5.5225e-05 - val_loss: 8.9249e-06 - val_mae: 9.8036e-04 - val_mse: 1.7850e-05\n",
            "Epoch 28/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7609e-05 - mae: 0.0013 - mse: 5.5217e-05 - val_loss: 9.0046e-06 - val_mae: 0.0011 - val_mse: 1.8009e-05\n",
            "Epoch 29/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7608e-05 - mae: 0.0013 - mse: 5.5217e-05 - val_loss: 8.8799e-06 - val_mae: 8.8545e-04 - val_mse: 1.7760e-05\n",
            "Epoch 30/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7618e-05 - mae: 0.0013 - mse: 5.5235e-05 - val_loss: 8.8932e-06 - val_mae: 9.1616e-04 - val_mse: 1.7786e-05\n",
            "Epoch 31/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7607e-05 - mae: 0.0013 - mse: 5.5213e-05 - val_loss: 9.1527e-06 - val_mae: 0.0013 - val_mse: 1.8305e-05\n",
            "Epoch 32/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7606e-05 - mae: 0.0013 - mse: 5.5212e-05 - val_loss: 9.0306e-06 - val_mae: 0.0011 - val_mse: 1.8061e-05\n",
            "Epoch 33/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7615e-05 - mae: 0.0013 - mse: 5.5230e-05 - val_loss: 8.8236e-06 - val_mae: 6.4703e-04 - val_mse: 1.7647e-05\n",
            "Epoch 34/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7610e-05 - mae: 0.0013 - mse: 5.5219e-05 - val_loss: 8.9487e-06 - val_mae: 0.0010 - val_mse: 1.7897e-05\n",
            "Epoch 35/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7618e-05 - mae: 0.0013 - mse: 5.5235e-05 - val_loss: 8.8916e-06 - val_mae: 9.1257e-04 - val_mse: 1.7783e-05\n",
            "Epoch 36/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7606e-05 - mae: 0.0013 - mse: 5.5212e-05 - val_loss: 9.2539e-06 - val_mae: 0.0014 - val_mse: 1.8508e-05\n",
            "Epoch 37/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7611e-05 - mae: 0.0013 - mse: 5.5222e-05 - val_loss: 9.1422e-06 - val_mae: 0.0013 - val_mse: 1.8284e-05\n",
            "Epoch 38/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7608e-05 - mae: 0.0013 - mse: 5.5217e-05 - val_loss: 8.9293e-06 - val_mae: 9.8872e-04 - val_mse: 1.7859e-05\n",
            "Epoch 39/40\n",
            "1922/1922 [==============================] - 29s 15ms/step - loss: 2.7621e-05 - mae: 0.0013 - mse: 5.5242e-05 - val_loss: 8.9430e-06 - val_mae: 0.0010 - val_mse: 1.7886e-05\n",
            "Epoch 40/40\n",
            "1922/1922 [==============================] - 30s 15ms/step - loss: 2.7609e-05 - mae: 0.0013 - mse: 5.5218e-05 - val_loss: 9.1020e-06 - val_mae: 0.0012 - val_mse: 1.8204e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from the location\n",
        "model = load_model(f'{ROOT_FOLDER}/date_time_model.h5')"
      ],
      "metadata": {
        "id": "_xbmrEKpU3E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test).round().astype(int)\n",
        "\n",
        "print(f\"\\nR2 score: {r2_score(y_test, predictions):.5f}\")\n",
        "print(f\"Mean squared error: {mean_squared_error(y_test, predictions):.5f}\\n\")\n",
        "print(f\"Mean absolute error: {mean_absolute_error(y_test, predictions):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4981be1c-437f-410c-b4dc-2a7286d82b4e",
        "id": "MDmKj5uHsRqv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6150/6150 [==============================] - 25s 4ms/step\n",
            "\n",
            "R2 score: -0.01706\n",
            "Mean squared error: 0.00006\n",
            "\n",
            "Mean absolute error: 0.00098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_timestamp, forecasted_dates_times = timestamp_validation_last, []\n",
        "\n",
        "# Add each predicted time interval to the previous timestamp to generate the next timestamp\n",
        "for interval in predictions:\n",
        "    interval_seconds = interval.item()\n",
        "    n_timestamp = curr_timestamp + pd.Timedelta(seconds=interval_seconds)\n",
        "    forecasted_dates_times.append(n_timestamp)\n",
        "    curr_timestamp = n_timestamp"
      ],
      "metadata": {
        "id": "SW2a6lwsViZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_intervals = pd.DataFrame({'test_date_time': df.iloc[-len(X_test):].date_time, 'predicted_date_time': forecasted_dates_times})\n",
        "df_intervals.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc41cc3c-f5c6-4ebd-e6e8-df2ce2e5da4f",
        "id": "pXQa8WvWsJye"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   test_date_time       predicted_date_time\n",
              "2262867 2010-12-01 16:35:40+00:00 2010-12-01 16:35:44+00:00\n",
              "2262868 2010-12-01 16:35:44+00:00 2010-12-01 16:35:44+00:00\n",
              "2262869 2010-12-01 16:35:50+00:00 2010-12-01 16:35:44+00:00\n",
              "2262870 2010-12-01 16:35:56+00:00 2010-12-01 16:35:44+00:00\n",
              "2262871 2010-12-01 16:35:58+00:00 2010-12-01 16:35:44+00:00\n",
              "2262872 2010-12-01 16:36:04+00:00 2010-12-01 16:35:44+00:00\n",
              "2262873 2010-12-01 16:36:13+00:00 2010-12-01 16:35:44+00:00\n",
              "2262874 2010-12-01 16:36:15+00:00 2010-12-01 16:35:44+00:00\n",
              "2262875 2010-12-01 16:36:19+00:00 2010-12-01 16:35:44+00:00\n",
              "2262876 2010-12-01 16:36:23+00:00 2010-12-01 16:35:44+00:00\n",
              "2262877 2010-12-01 16:36:24+00:00 2010-12-01 16:35:44+00:00\n",
              "2262878 2010-12-01 16:36:28+00:00 2010-12-01 16:35:44+00:00\n",
              "2262879 2010-12-01 16:36:31+00:00 2010-12-01 16:35:44+00:00\n",
              "2262880 2010-12-01 16:36:34+00:00 2010-12-01 16:35:44+00:00\n",
              "2262881 2010-12-01 16:36:35+00:00 2010-12-01 16:35:44+00:00\n",
              "2262882 2010-12-01 16:36:36+00:00 2010-12-01 16:35:44+00:00\n",
              "2262883 2010-12-01 16:36:37+00:00 2010-12-01 16:35:44+00:00\n",
              "2262884 2010-12-01 16:36:52+00:00 2010-12-01 16:35:44+00:00\n",
              "2262885 2010-12-01 16:36:53+00:00 2010-12-01 16:35:44+00:00\n",
              "2262886 2010-12-01 16:36:55+00:00 2010-12-01 16:35:44+00:00\n",
              "2262887 2010-12-01 16:37:02+00:00 2010-12-01 16:35:44+00:00\n",
              "2262888 2010-12-01 16:37:06+00:00 2010-12-01 16:35:44+00:00\n",
              "2262890 2010-12-01 16:37:08+00:00 2010-12-01 16:35:44+00:00\n",
              "2262889 2010-12-01 16:37:08+00:00 2010-12-01 16:35:44+00:00\n",
              "2262891 2010-12-01 16:37:10+00:00 2010-12-01 16:35:44+00:00\n",
              "2262892 2010-12-01 16:37:17+00:00 2010-12-01 16:35:44+00:00\n",
              "2262893 2010-12-01 16:37:19+00:00 2010-12-01 16:35:44+00:00\n",
              "2262894 2010-12-01 16:37:23+00:00 2010-12-01 16:35:44+00:00\n",
              "2262895 2010-12-01 16:37:24+00:00 2010-12-01 16:35:44+00:00\n",
              "2262896 2010-12-01 16:37:25+00:00 2010-12-01 16:35:44+00:00\n",
              "2262897 2010-12-01 16:37:27+00:00 2010-12-01 16:35:44+00:00\n",
              "2262898 2010-12-01 16:37:34+00:00 2010-12-01 16:35:44+00:00\n",
              "2262899 2010-12-01 16:37:37+00:00 2010-12-01 16:35:44+00:00\n",
              "2262900 2010-12-01 16:37:39+00:00 2010-12-01 16:35:44+00:00\n",
              "2262901 2010-12-01 16:37:40+00:00 2010-12-01 16:35:44+00:00\n",
              "2262902 2010-12-01 16:37:44+00:00 2010-12-01 16:35:44+00:00\n",
              "2262903 2010-12-01 16:37:49+00:00 2010-12-01 16:35:44+00:00\n",
              "2262904 2010-12-01 16:37:51+00:00 2010-12-01 16:35:44+00:00\n",
              "2262905 2010-12-01 16:37:51+00:00 2010-12-01 16:35:44+00:00\n",
              "2262906 2010-12-01 16:37:54+00:00 2010-12-01 16:35:44+00:00\n",
              "2262907 2010-12-01 16:37:57+00:00 2010-12-01 16:35:44+00:00\n",
              "2262908 2010-12-01 16:37:58+00:00 2010-12-01 16:35:44+00:00\n",
              "2262909 2010-12-01 16:38:03+00:00 2010-12-01 16:35:44+00:00\n",
              "2262910 2010-12-01 16:38:05+00:00 2010-12-01 16:35:44+00:00\n",
              "2262911 2010-12-01 16:38:08+00:00 2010-12-01 16:35:44+00:00\n",
              "2262912 2010-12-01 16:38:09+00:00 2010-12-01 16:35:44+00:00\n",
              "2262913 2010-12-01 16:38:10+00:00 2010-12-01 16:35:44+00:00\n",
              "2262914 2010-12-01 16:38:11+00:00 2010-12-01 16:35:44+00:00\n",
              "2262915 2010-12-01 16:38:12+00:00 2010-12-01 16:35:44+00:00\n",
              "2262916 2010-12-01 16:38:13+00:00 2010-12-01 16:35:44+00:00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a36f6e61-d33d-465c-b9ed-1383ccd74fd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_date_time</th>\n",
              "      <th>predicted_date_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2262867</th>\n",
              "      <td>2010-12-01 16:35:40+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262868</th>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262869</th>\n",
              "      <td>2010-12-01 16:35:50+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262870</th>\n",
              "      <td>2010-12-01 16:35:56+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262871</th>\n",
              "      <td>2010-12-01 16:35:58+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262872</th>\n",
              "      <td>2010-12-01 16:36:04+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262873</th>\n",
              "      <td>2010-12-01 16:36:13+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262874</th>\n",
              "      <td>2010-12-01 16:36:15+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262875</th>\n",
              "      <td>2010-12-01 16:36:19+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262876</th>\n",
              "      <td>2010-12-01 16:36:23+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262877</th>\n",
              "      <td>2010-12-01 16:36:24+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262878</th>\n",
              "      <td>2010-12-01 16:36:28+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262879</th>\n",
              "      <td>2010-12-01 16:36:31+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262880</th>\n",
              "      <td>2010-12-01 16:36:34+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262881</th>\n",
              "      <td>2010-12-01 16:36:35+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262882</th>\n",
              "      <td>2010-12-01 16:36:36+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262883</th>\n",
              "      <td>2010-12-01 16:36:37+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262884</th>\n",
              "      <td>2010-12-01 16:36:52+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262885</th>\n",
              "      <td>2010-12-01 16:36:53+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262886</th>\n",
              "      <td>2010-12-01 16:36:55+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262887</th>\n",
              "      <td>2010-12-01 16:37:02+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262888</th>\n",
              "      <td>2010-12-01 16:37:06+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262890</th>\n",
              "      <td>2010-12-01 16:37:08+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262889</th>\n",
              "      <td>2010-12-01 16:37:08+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262891</th>\n",
              "      <td>2010-12-01 16:37:10+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262892</th>\n",
              "      <td>2010-12-01 16:37:17+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262893</th>\n",
              "      <td>2010-12-01 16:37:19+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262894</th>\n",
              "      <td>2010-12-01 16:37:23+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262895</th>\n",
              "      <td>2010-12-01 16:37:24+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262896</th>\n",
              "      <td>2010-12-01 16:37:25+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262897</th>\n",
              "      <td>2010-12-01 16:37:27+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262898</th>\n",
              "      <td>2010-12-01 16:37:34+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262899</th>\n",
              "      <td>2010-12-01 16:37:37+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262900</th>\n",
              "      <td>2010-12-01 16:37:39+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262901</th>\n",
              "      <td>2010-12-01 16:37:40+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262902</th>\n",
              "      <td>2010-12-01 16:37:44+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262903</th>\n",
              "      <td>2010-12-01 16:37:49+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262904</th>\n",
              "      <td>2010-12-01 16:37:51+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262905</th>\n",
              "      <td>2010-12-01 16:37:51+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262906</th>\n",
              "      <td>2010-12-01 16:37:54+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262907</th>\n",
              "      <td>2010-12-01 16:37:57+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262908</th>\n",
              "      <td>2010-12-01 16:37:58+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262909</th>\n",
              "      <td>2010-12-01 16:38:03+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262910</th>\n",
              "      <td>2010-12-01 16:38:05+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262911</th>\n",
              "      <td>2010-12-01 16:38:08+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262912</th>\n",
              "      <td>2010-12-01 16:38:09+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262913</th>\n",
              "      <td>2010-12-01 16:38:10+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262914</th>\n",
              "      <td>2010-12-01 16:38:11+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262915</th>\n",
              "      <td>2010-12-01 16:38:12+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262916</th>\n",
              "      <td>2010-12-01 16:38:13+00:00</td>\n",
              "      <td>2010-12-01 16:35:44+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a36f6e61-d33d-465c-b9ed-1383ccd74fd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a36f6e61-d33d-465c-b9ed-1383ccd74fd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a36f6e61-d33d-465c-b9ed-1383ccd74fd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ba2ba67a-baab-4ebd-aec2-6ae4a0fb02ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba2ba67a-baab-4ebd-aec2-6ae4a0fb02ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ba2ba67a-baab-4ebd-aec2-6ae4a0fb02ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_intervals"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "amQvdClrwgoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Predicting number of students\n",
        "\n",
        "1. In this task, I've used `MinMaxScaler` on the `users` column.\n",
        "2. I've used two `LSTM` layers with `50 units` and `relu` activation function.\n",
        "3. During compilation of the model, I've placed a callback (ModelCheckpoint) which will store the model in the file `num_of_students.h5`.\n",
        "4. `'Adam'` optimizer was used as a part of the compilation.\n",
        "4. Later I've tested the model using prediction on the testing dataset.\n",
        "5. Once I got the output from the prediction, later I've used `inverse_tranform` to get the actual values.\n",
        "6. Lastly, I've converted the data into `int` format to get the accurate number of student."
      ],
      "metadata": {
        "id": "Vm98SM7xkodV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGStsxYrWsY5"
      },
      "outputs": [],
      "source": [
        "# normalisation using MinMax scaler for 'users' column\n",
        "users_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['users'] = users_scaler.fit_transform(df['users'].values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooveoj8mWtP3"
      },
      "outputs": [],
      "source": [
        "# Create new sequences\n",
        "seq_length = 5\n",
        "def new_sequences(df, seq_length):\n",
        "    Xs, Ys = [], []\n",
        "    for i in range(len(df) - seq_length):\n",
        "        y = df[i + seq_length]\n",
        "        x = df[i:(i + seq_length)].tolist()\n",
        "        Ys.append(y)\n",
        "        Xs.append(x)\n",
        "    return np.array(Xs), np.array(Ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNJoUYfsX5qu"
      },
      "outputs": [],
      "source": [
        "# dataset for LSTM with 'users' as target variable\n",
        "X, y = new_sequences(df['users'].values, seq_length)\n",
        "\n",
        "# Chronological splitting of time series dataset into training, and testing datasets\n",
        "n = len(df)\n",
        "X_train, X_test = X[0:int(n*0.8)], X[int(n*0.8):]\n",
        "y_train, y_test = y[0:int(n*0.8)], y[int(n*0.8):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhIB-H8oX5ov"
      },
      "outputs": [],
      "source": [
        "# Reshaping - [samples, time_steps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5uIZl5rX5m6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c005ff-466a-4aa9-a3be-7fb32c7bf783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Model Compilation\n",
        "opt = 'adam'\n",
        "model.compile(optimizer = opt, loss = 'mean_squared_error')\n",
        "\n",
        "# Checkpoint creation\n",
        "checkpoint = ModelCheckpoint(f'{ROOT_FOLDER}/num_of_students.h5', save_best_only=True, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdRPln-2X5k9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af99612-7192-4347-a17a-8ff7005a6ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "27671/27671 [==============================] - 252s 9ms/step - loss: 9.0251e-04 - val_loss: 6.5154e-05\n",
            "Epoch 2/20\n",
            "27671/27671 [==============================] - 247s 9ms/step - loss: 6.2967e-04 - val_loss: 2.3212e-05\n",
            "Epoch 3/20\n",
            "27671/27671 [==============================] - 247s 9ms/step - loss: 6.2063e-04 - val_loss: 2.6612e-05\n",
            "Epoch 4/20\n",
            "27671/27671 [==============================] - 247s 9ms/step - loss: 6.1511e-04 - val_loss: 4.4649e-05\n",
            "Epoch 5/20\n",
            "27671/27671 [==============================] - 252s 9ms/step - loss: 6.1042e-04 - val_loss: 3.4982e-05\n",
            "Epoch 6/20\n",
            "27671/27671 [==============================] - 256s 9ms/step - loss: 6.0796e-04 - val_loss: 1.0369e-05\n",
            "Epoch 7/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 6.0611e-04 - val_loss: 1.9211e-05\n",
            "Epoch 8/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 6.0392e-04 - val_loss: 1.6441e-05\n",
            "Epoch 9/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 6.0388e-04 - val_loss: 1.3662e-05\n",
            "Epoch 10/20\n",
            "27671/27671 [==============================] - 254s 9ms/step - loss: 6.0038e-04 - val_loss: 2.3499e-05\n",
            "Epoch 11/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 5.9847e-04 - val_loss: 2.9916e-05\n",
            "Epoch 12/20\n",
            "27671/27671 [==============================] - 254s 9ms/step - loss: 5.9904e-04 - val_loss: 1.4247e-05\n",
            "Epoch 13/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 5.9876e-04 - val_loss: 1.0913e-05\n",
            "Epoch 14/20\n",
            "27671/27671 [==============================] - 256s 9ms/step - loss: 5.9894e-04 - val_loss: 1.0031e-05\n",
            "Epoch 15/20\n",
            "27671/27671 [==============================] - 256s 9ms/step - loss: 5.9829e-04 - val_loss: 4.8645e-05\n",
            "Epoch 16/20\n",
            "27671/27671 [==============================] - 256s 9ms/step - loss: 5.9657e-04 - val_loss: 5.9848e-06\n",
            "Epoch 17/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 5.9652e-04 - val_loss: 1.9973e-05\n",
            "Epoch 18/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 5.9698e-04 - val_loss: 1.9517e-05\n",
            "Epoch 19/20\n",
            "27671/27671 [==============================] - 254s 9ms/step - loss: 5.9552e-04 - val_loss: 9.1172e-06\n",
            "Epoch 20/20\n",
            "27671/27671 [==============================] - 255s 9ms/step - loss: 5.9552e-04 - val_loss: 2.8497e-05\n"
          ]
        }
      ],
      "source": [
        "model2 = model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=20,\n",
        "            batch_size=64,\n",
        "            validation_split=0.1,\n",
        "            callbacks=[checkpoint],\n",
        "            verbose=1\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFXAeD2YX5jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c14f24c-26e6-4bb0-8cc6-fb78192005a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15373/15373 [==============================] - 38s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# saving model with .h5 extension\n",
        "model = load_model(f'{ROOT_FOLDER}/num_of_students.h5')\n",
        "\n",
        "# evaluation on test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Inverse transformation\n",
        "predictions = users_scaler.inverse_transform(predictions)\n",
        "\n",
        "# Inverse transform to actual test set\n",
        "test_y_inverse = users_scaler.inverse_transform(y_test.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KW2XpRVX5gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4e3300-85c8-42b4-9606-ad8c0d344718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting the last 100 records in the test set:\n",
            "\n",
            "    actual  predicted\n",
            "0       23         27\n",
            "1       22         28\n",
            "2       23         29\n",
            "3       22         29\n",
            "4       21         30\n",
            "..     ...        ...\n",
            "95       2         11\n",
            "96       3         11\n",
            "97       2         11\n",
            "98       1         11\n",
            "99       0         11\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "test_y_inverse = list(test_y_inverse.flatten()[-100:])\n",
        "test_y_inverse = list(np.round(test_y_inverse).astype(int))\n",
        "predictions = list(predictions.flatten()[-100:])\n",
        "predictions = list(np.round(predictions).astype(int))\n",
        "\n",
        "test_y_inverse_df = pd.DataFrame(test_y_inverse, columns=['actual'])\n",
        "predictions_df = pd.DataFrame(predictions, columns=['predicted'])\n",
        "\n",
        "df_pred = pd.concat([test_y_inverse_df, predictions_df], axis=1)\n",
        "\n",
        "print(\"Predicting the last 100 records in the test set:\\n\")\n",
        "\n",
        "print(df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEateEB9YBvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f04b2de-34ef-41ff-fbd9-53b0d70ad630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 78.75\n",
            "\n",
            "Mean Absolute Error: 8.75\n",
            "\n",
            "R^2 Score: -1.7002839155659797\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# accuracy calculation\n",
        "mse_value = mean_squared_error(test_y_inverse, predictions)\n",
        "mae_value = mean_absolute_error(test_y_inverse, predictions)\n",
        "r2 = r2_score(test_y_inverse, predictions)\n",
        "\n",
        "# Printing accuracy\n",
        "print(f'Mean Squared Error: {mse_value}\\n')\n",
        "print(f'Mean Absolute Error: {mae_value}\\n')\n",
        "print(f'R^2 Score: {r2}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GiQpJ_y1wWGR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYw10_C3WuYd"
      },
      "source": [
        "## 5. Predicting Cluster\n",
        "\n",
        "1. Firstly, I've created numerical features like `hour, minute, day, month, year, day_of_week` from *date_time* to predict clusters.\n",
        "2. I've utilised `LSTM` layer and one `BatchNormalization` layer. The `units` in the layer are ranges from 64 to 32. The `relu` activation function was used.\n",
        "3. The last layer has `softmax` activation function because this approach is of classification.\n",
        "4. During compilation, `'Adam'` optimization was used.\n",
        "5. Following are the metrices I've got:\n",
        "\n",
        "    Accuracy: 0.113\n",
        "    \n",
        "    Precision: 0.059\n",
        "    \n",
        "    Recall: 0.113\n",
        "    \n",
        "    F1 Score: 0.045"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYaiCvc2Wv6j"
      },
      "outputs": [],
      "source": [
        "# Convert date time into numerical features (hour, minute, day, month, year, day_of_week):\n",
        "df['hour'] = df['date_time'].map(lambda x: x.hour)\n",
        "df['minute'] = df['date_time'].map(lambda x: x.minute)\n",
        "df['day'] = df['date_time'].map(lambda x: x.day)\n",
        "df['month'] = df['date_time'].map(lambda x: x.month)\n",
        "df['year'] = df['date_time'].map(lambda x: x.year)\n",
        "df['day_of_week'] = df['date_time'].map(lambda x: x.isoweekday() % 7)\n",
        "\n",
        "df.drop(columns=['date_time'], inplace=True)\n",
        "\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df[['duration', 'year', 'month', 'day', 'hour', 'minute', 'day_of_week']]\n",
        "y = df['cluster']\n",
        "\n",
        "# Standardize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode target variable\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkfO0H7KXbqn"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(0.8 * len(df))\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Standardize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape input data for LSTM\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DqqLUkZXboR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2481467e-d916-4620-e883-2a736acf8a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(np.unique(y)), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmvrvrn8XbmM",
        "outputId": "39dead7e-6c23-440c-fb2f-d0d8c2e95577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 7, 64)             16896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 64)             0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32)                128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 37)                1221      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31717 (123.89 KB)\n",
            "Trainable params: 31653 (123.64 KB)\n",
            "Non-trainable params: 64 (256.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(f'{ROOT_FOLDER}/cluster_names.h5', monitor='sparse_categorical_crossentropy', mode='min')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6TAosNeXjaN",
        "outputId": "5fa7eda7-8cd5-4514-87a9-bd9f8c9ff3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3844/3844 [==============================] - 53s 12ms/step - loss: 3.2210 - accuracy: 0.1168\n",
            "Epoch 2/10\n",
            "3844/3844 [==============================] - 46s 12ms/step - loss: 3.1324 - accuracy: 0.1236\n",
            "Epoch 3/10\n",
            "3844/3844 [==============================] - 46s 12ms/step - loss: 3.1063 - accuracy: 0.1261\n",
            "Epoch 4/10\n",
            "3844/3844 [==============================] - 46s 12ms/step - loss: 3.0841 - accuracy: 0.1280\n",
            "Epoch 5/10\n",
            "3844/3844 [==============================] - 45s 12ms/step - loss: 3.0676 - accuracy: 0.1301\n",
            "Epoch 6/10\n",
            "3844/3844 [==============================] - 44s 12ms/step - loss: 3.0531 - accuracy: 0.1321\n",
            "Epoch 7/10\n",
            "3844/3844 [==============================] - 45s 12ms/step - loss: 3.0447 - accuracy: 0.1331\n",
            "Epoch 8/10\n",
            "3844/3844 [==============================] - 45s 12ms/step - loss: 3.0387 - accuracy: 0.1337\n",
            "Epoch 9/10\n",
            "3844/3844 [==============================] - 44s 12ms/step - loss: 3.0341 - accuracy: 0.1345\n",
            "Epoch 10/10\n",
            "3844/3844 [==============================] - 46s 12ms/step - loss: 3.0302 - accuracy: 0.1348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=512, verbose=1, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y51vLPGkXjX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f429d5-919b-4492-82e9-2afcc2140fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15373/15373 [==============================] - 45s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29, 29, 29, ...,  9,  9,  9])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = load_model(f'{ROOT_FOLDER}/cluster_names.h5')\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eato8cmGXt8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc2e31e-6a82-4c1a-c957-0fa56fe33411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11337431494039778\n",
            "Precision: 0.05934853052605717\n",
            "Recall: 0.11337431494039778\n",
            "F1 Score: 0.04508880758307765\n"
          ]
        }
      ],
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSYMBYhHXt6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db49c51-90ae-4ebb-923e-a04262a973eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next 100 cluster values:\n",
            "[29 15 28 28 28 15 15 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
            " 28 28 28 28]\n"
          ]
        }
      ],
      "source": [
        "# Predict the next 100 cluster values\n",
        "next_values = []\n",
        "last_X = X_train_reshaped[-1:].copy()  # Use the last training sample as the initial input for prediction\n",
        "\n",
        "for _ in range(100):\n",
        "    # Predict the next cluster value\n",
        "    next_value = model.predict(last_X.reshape(1, X_train_reshaped.shape[1], 1), verbose=0)\n",
        "    next_value = np.argmax(next_value, axis=1)\n",
        "\n",
        "    next_values.append(next_value)\n",
        "\n",
        "    # Update the input for the next prediction\n",
        "    last_X[0, :-1, 0] = last_X[0, 1:, 0]  # Shift the existing values to the left\n",
        "    last_X[0, -1, 0] = next_value          # Append the predicted value at the end\n",
        "\n",
        "# Convert predicted cluster values back to original labels\n",
        "predicted_clusters = encoder.inverse_transform(next_values)\n",
        "\n",
        "print(\"Predicted next 100 cluster values:\")\n",
        "print(predicted_clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mirrHLwLXxfI"
      },
      "source": [
        "---"
      ]
    }
  ]
}